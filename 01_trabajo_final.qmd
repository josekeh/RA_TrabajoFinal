---
title: "Trabajo Pr치ctico Final"
format:
  html:
    embed-resources: true
lang: es 
editor: visual
editor_options: 
  chunk_output_type: console
execute: 
  echo: false
  warning: false
  error: true
---

```{=html}
<style>
@media print {
  button {
    display: none;
  }
}
</style>
```
<button onclick="window.print()">

游늯 Exportar a PDF

</button>

# Introducci칩n

El b치squetbol es uno de los deportes m치s populares en los Estados Unidos. Adem치s de su destacad칤sima liga masculina NBA, se encuentra su similar femenina, la altamente competitiva, WNBA. El siguiente trabajo busca demostrar conocimientos aprendidos en la materia Regresi칩n avanzada a partir de un dataset de esta ultima liga mencionada.

# Dataset

```{r}
# Librer칤as
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(broom)
library(egg)
library(ggpubr)
library(car)
library(glmnet)
library(caret)
library(pROC)
```

## Importaci칩n de datos

Se procede a cargar los datos y a mostrar un summary de los mismos:

```{r}
data <- read.csv("files/WNBA.csv", sep = ";")
summary(data)
```

```{r}
data$Equipo <- as.factor(data$Equipo)
data$Posicion <- as.factor(data$Posicion)
summary(data)
```

## Breve an치lisis

Luego de importar los datos, se procede a hacer un breve an치lisis.

### Vac칤os y duplicados

A trav칠s del summary se puede ver que las variables num칠ricas est치n correctamente definidas, sin NAs. Los mismo para Equipo y Posici칩n. Se procede a analizar si existen jugadoras campo Jugadora vac칤o. El resultado de aplicar los filtros correspondientes es el siguiente:

```{r}
paste0("Hay ",count(data %>% filter(Jugadora == "")), " registros vac칤os")
```

Una vez checkeado esto, viendo que no hay vac칤os, vemos si hay alguna jugadora repetida.

```{r}
data[duplicated(data$Jugadora),][,c("Jugadora", "Equipo")]
```

Vemos que existen jugadoras que aparecen m치s de una vez, pero parece ser que se encuentran en equipos diferentes. Para eso, contamos la cantidad de veces que se encuentra duplicado Jugadora + Equipo, con el resultado que sigue:

```{r}
print(count(data[duplicated(data[, c("Jugadora", "Equipo")]), ]))
```

Por ende, podemos entender que cada vez que aparece una jugadora se da en otro club. Esto tambi칠n puede llevar a diferentes condiciones de goleo como as칤 tambi칠n otro momento de la carrera profesional, por lo que se decide conservar los datos tal cual se encuentran.

### Entendiendo el dataset

Una vez avanzada la etapa anterior, vamos a ver brevemente c칩mo se encuentran distribuidos los datos.

```{r}
ggplot(data, aes(x = Equipo)) +
  geom_bar(fill = "grey", color = "black") +
  labs(title = "Equipos",
       x = "Equipo",
       y = "Frecuencia") +
  theme_minimal()
```

```{r}
ggplot(data, aes(x = Posicion)) +
  geom_bar(fill = "grey", color = "black") +
  labs(title = "Equipos",
       x = "Posici칩n",
       y = "Frecuencia") +
  theme_minimal()
```

Se puede observar como es similar la distribuci칩n de jugadoras por equipo, mientras que abundan mayormente posiciones de Escolta, seguido de Alero y luego Pivot. El tener pocos datos de Pivots no es algo irracional, ya que es es la posici칩n que menos jugadoras suele haber.

```{r}
skimr::skim(data %>% select(where(is.numeric)))
```

Analizando las variables cuantitativas vemos en primer lugar que no hay valores negativos, lo cual es coherente y requerido. Mientras que la mayor칤a de las distribuciones son asim칠tricas hacia la derecha, se puede observar como la cantidad de juegos es la 칰nica que no respeta este patr칩n. Resulta apropiado ver c칩mo el histograma de dobles y triples es muy parecido en la forma de la distribuci칩n como as칤 tambi칠n el resultante natural de los puntos.

Tambi칠n es interesante comparar medias de Triples y Dobles con Puntos. Si se realizar r치pidamente Triples x 3 + Dobles x 2 (en medias), se obtiene un valor de 186.7, lejano al 226 de los Puntos, por lo que podr칤amos entender, a priori, que los libres (tiros individuales de 1 punto) tiene peso en el goleo de las jugadoras.

# Modelos de Regresi칩n Lineal

Para comenzar a trabajar en los modelos de regresi칩n lineal, se procede a dividir el dataset en train/test. Se define una semilla para hacer reproducible el experimento y se define, por consigna, que el train contenga el 70% de los datos, mientras que lo restante queda para test.

```{r}
# Divisi칩n en training y testing
set.seed(45672848)
index_training <- sample(1:nrow(data), size = 0.7*nrow(data))

training <- data[index_training,]
testing <- data[-index_training,]
```

Se procede, luego, a obtener tres modelos mediante los siguientes criterios: - Usando stepwise regression - Criterios propios - Preguntando al famoso ChatGPT

## Stepwise regression

Para el primer caso se busca obtener un modelo de regresi칩n en el que las variables a utilizar se definan por el proceso autom치tico de Stepwise regression, ya que utilizar la t칠cnica del mejor subconjunto llevar칤a a un n칰mero muy grande de modelos a comprar y se opta por esta t칠cnica que si bien no garantiza encontrar el 칩ptimo, puede darnos una buena primera aproximaci칩n. Para el an치lisis se quitan del dataset el nombre de la jugadora y el equipo, ya que dichas variables cuentan con una gran cantidad de categor칤as. En caso de incluirlas, se obtendr칤an estimaciones muy pobres debido a los escasos grados de libertad, o incluso podr칤a llegar el caso que sea imposible estimar el modelo.

```{r}
training_filtered <- select(training, -Jugadora, -Equipo)
m1 <- MASS::stepAIC(
  object = lm(Puntos ~ 1, data = training_filtered), #punto de partida
  scope = list(upper = lm(Puntos ~ ., data = training_filtered)), #m치ximo modelo posible
  direction = "both", #m칠todo de selecci칩n
  trace = FALSE, #para no imprimir resultados parciales
  k = 2, #penalizaci칩n a emplear (2 = AIC, log(n) = BIC)
  steps = 1000 #m치ximo nro de pasos
  )

summary(m1)
```

El resultado devuelve la utilizaci칩n de Dobles, Triples, Robos y Juegos.

## Criterios propios

Observando el dataset, se plantea un modelo donde los puntos se basen en dobles y triples, y debido a que deber칤a de haber una diferencia (por los libres), se plantea la posici칩n, la cual determinar칤a la tendencia de un jugador a recibir faltas de tiro.

```{r}
m2 <- lm(Puntos ~ Dobles + Triples + Posicion, data = training_filtered)

summary(m2)
```

## ChatGPT

Para este tercer modelo, se le ha preguntado (o desafiado) a ChatGPT a recomendar cu치l ser칤a el mejor modelo. La respuesta fue incluir Dobles, Triples, Minutos, Asistencias, Rebotes y Posicion.

```{r}
m3 <- lm(Puntos ~ Triples + Dobles + Minutos + Asistencias + Rebotes + Posicion, data = training)
summary(m3)
```

## Comparaci칩n de modelos

Se procede a comparar los modelos planteados comparando CME, PRESS, Cp, AIC y BIC.

```{r}
modelos <- data.frame(Modelo = c("Modelo 1", "Modelo 2", "Modelo 3"),
                      Ajuste = c("m1", "m2", "m3"))
```

```{r}
Modelo_completo <- lm(Puntos ~ . -Jugadora - Equipo, data = training)
sigma <- sum(residuals(Modelo_completo)^2)/df.residual(Modelo_completo)

Resumen <- modelos %>% 
  group_by(Modelo) %>% 
  summarise(CME = summary(get(Ajuste))$sigma^2,
            PRESS = sum((resid(get(Ajuste))/(1-hatvalues(get(Ajuste))))^2),
            Cp = sum(residuals(get(Ajuste))^2)/sigma + 2 * length(coef(get(Ajuste))) - nrow(training),
            AIC = AIC(get(Ajuste)),
            BIC = BIC(get(Ajuste)))

kable(Resumen, caption = "Tabla N춿1: Comparaci칩n del ajuste de los 3 modelos") %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

Con los datos obtenidos se puede pensar en elegir entre el Modelo 1 y Modelo 2. El Modelo 1 es el que mejores resultados en las m칠tricas de performance, mientras que el Modelo 2 es apenas peor, pero es m치s simple. Para este caso, se decide quedarse con el Modelo 1.

## An치lisis de residuos

Ya con el Modelo 1 elegido, se procede a evaluar los supuestos a trav칠s de los residuos.

```{r}
Modelo_final <- augment(m1)
g1 <- ggplot(mapping = aes(sample = Modelo_final$.resid)) + 
    stat_qq(color = "dodgerblue") + 
    stat_qq_line() + 
  ggtitle("QQ Normal") +
  xlab("Cuantiles te칩ricos") +
  ylab("Cuantiles muestrales") +
  geom_text(aes(x = 2, y = -50, fill ="black", label = paste0("p-value \n", round(shapiro.test(Modelo_final$.resid)$p.value, 8)))) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "none")

g2 <- ggplot(Modelo_final) +
  aes(x = .fitted, y = .std.resid) +
  geom_point(color = "dodgerblue") +
  geom_hline(yintercept = 0, color = "black") +
  ggtitle("Residuos vs. Predichos") +
  xlab("Valores predichos") +
  ylab("Residuos estandarizados") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

g <- ggarrange(g1, g2, ncol = 2)

annotate_figure(g, top = text_grob("Gr치fico N춿1: Comprobaci칩n de supuestos", face = "bold", size = 14))
```

En el gr치fico N춿1 se observa que la distribuci칩n de los mismos presenta colas pesadas y que no se verifica el supuesto de variancia constante. En caso de querer solucionarlo, podr칤a optarse por utilizar una transformaci칩n de la variables respuesta como el $log(Y)$ o bien aplicar el m칠todo de Box y Cox. Por otro lado, tambi칠n se observa a un posible valor at칤pico.

Luego se procede a analizar colinealidad

```{r}
# Colinealidad
training_modelo <- training %>% 
  select(Juegos, Minutos, Triples, Dobles)

corr_matrix <- cor(training_modelo)

corr_melted <- reshape2::melt(corr_matrix)

ggplot(corr_melted, aes(x = Var2, y = Var1, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), size = 3) +
  scale_fill_gradient2(low = "#ef2947", high = "#009929", mid = "white", midpoint = 0) +
  labs(x = "", y = "", title = "Gr치fico N춿2: Matriz de correlaci칩n") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

Analizando las correlaciones lineales entre variables se observa que minutos est치 muy relacionada linealmente con todas las restantes.

```{r}
vif = vif(m1)

vif_df <- data.frame(Variable = names(vif),
                     VIF = as.numeric(vif),
                     row.names = NULL)

kable(vif_df, caption = "Tabla N춿2: Factores de Inflaci칩n de la Varianza (VIF)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

Al analizar la tabla N춿2, se ve que, a pesar de que las variables est칠n altamente correlacionadas, esto no tiene un impacto tan importante ya que ning칰n VIF es mayor a 5.

```{r}
# Observaciones at칤picas
Modelo_final <- mutate(Modelo_final, 
                       PRESS = .resid/(1-.hat),
                       id = 1:nrow(Modelo_final))

g1 <- ggplot(data = Modelo_final) + 
    aes(x = id, y = PRESS) + 
  geom_bar(stat="identity", color = "dodgerblue", fill = "dodgerblue")+
    geom_hline(aes(yintercept = 0)) +
    ggtitle("Residuos PRESS") +
    xlab("Observaci칩n") +
    ylab("PRESS") +
    theme_bw() +
    theme(legend.position = "none",
          plot.title = element_text(hjust = 0.5))

# Observaciones influyentes
g2 <- ggplot(data = Modelo_final) +
    aes(x = id, y = .cooksd) +
  geom_bar(stat="identity", color = "dodgerblue", fill = "dodgerblue")+
    ggtitle("Distancia de Cook") +
    xlab("Observaci칩n") +
    ylab("Distancia de Cook") +
    theme_bw() +
    theme(legend.position = "none",
      plot.title = element_text(hjust = 0.5))

g <- ggarrange(g1, g2, ncol = 2)

annotate_figure(g, top = text_grob("Gr치fico N춿3: Observaciones at칤picas e influyentes", face = "bold", size = 14))
```

En el gr치fico N춿3 se vuelve a ver que existe una observaci칩n at칤pica, la cual presenta un residuo PRESS mayor a 100. Sin embargo, al analizar la influencia de las observaciones mediante la distancia de Cook, se encuentra que ninguna tiene una influencia desmedida sobre el ajuste del modelo, ya que todas son menores a 1.

## Interpretaci칩n del modelo

```{r}
Betas = data.frame(Variable = names(coef(m1)),
                   Valor = as.numeric(coef(m1)),
                   P_value = as.numeric(coef(summary(m1))[, "Pr(>|t|)"]))

kable(Betas, caption = "Tabla N춿3: Coeficientes estimados del modelo") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

A trav칠s de la Tabla N춿3 se puede interpretar nuestro modelo elegido:

-   El valor estimado del intercepto es de 2.68 aproximadamente. Igual as칤, el pvalue resulta de no poder descartar la hip칩tesis de que el intercepto es igual a 0. Recordando la interpretaci칩n del mismo, se pensar칤a que es el valor de puntos promedio para 0 dobles, 0 triples, 0 robos y 0 juegos. Lo cual no resulta para nada il칩gico pensar que este valor sea 0 en la realidad y que estad칤sticamente nos de dicho indicio.

Los dem치s predictores tienen un pvalue \<0.01, algunos con ordenes mucho menores, por lo que podemos rechazar la hipotesis de nula. Respecto a sus valores predichos podemos decir que:

-   Por cada doble convertido, los puntos de una jugadora aumentan en promedio en una suma de 2.40, manteniendose todas las dem치s variables constantes.
-   Por cada triple convertido, los puntos de una jugadora aumentan en promedio en una suma de 3.46, manteniendose todas las dem치s variables constantes.
-   Por cada robo conseguido, los puntos de una jugadora aumentan en promedio en una suma de 0.74, manteniendose todas las dem치s variables constantes.
-   Por cada juego jugado, los puntos de una jugadora disminuyen en promedio en una suma de 0.51, manteniendose todas las dem치s variables constantes.

Estas interpretaciones nos dejan insights interesantes de analizar. Si bien dobles y triples suman 2 y 3 puntos respectivamente en el juego, que el valor que afectan al promedio sea mayor puede estar indicando que en cierto modo, estos coeficientes est치n absorbiendo el efecto de los tiros libres. Lo mismo podemos pensar acerca del robo, ya que cuando se da el mismo, en el desorden del juego, es probable que quien roba reciba una falta. Por 칰ltimo, el valor al aumentar la cantidad de juegos podr칤a estar dando indicio de desgaste f칤sico de las jugadoras, o bien podr칤a ser que, a pesar de haber encontrado que la multicolinealidad no era muy importante, en realidad si nos est치 afectando a la estimaci칩n de este coeficiente, que a priori uno esperar칤a que fuera positivo.

# M칠todos de Regularizaci칩n

Una vez identificado el mejor modelo de regresi칩n con el ajuste de m칤nimos cuadrados ordinarios, se opt칩 por evaluar la posibilidad de utilizar m칠todos de regularizaci칩n. Esto se hizo con el objetivo de intentar mejorar la capacidad predictiva, bas치ndose en la idea del *trade-off* entre sesgo y variancia.

Para realizar tanto el ajuste mediante la regresi칩n ridge, como por el m칠todo de lasso, primero se busc칩 el mejor valor de $\lambda$ utilizando *5-fold Cross-Validation.*

Los resultados de los ajustes junto con los valores de $\lambda$ utilizados, son presentados a continuaci칩n:

```{r}
# Preparamos la matriz de predictores
training_X <- training %>% 
  select(Dobles, Triples, Robos, Juegos) %>% 
  as.matrix()

# Buscamos el lambda 칩ptimo para ridge y lasso
lambda_ridge <- cv.glmnet(training_X, training$Puntos, nfolds = 5, alpha = 0)$lambda.min 

lambda_lasso <- cv.glmnet(training_X, training$Puntos, nfolds = 5, alpha = 1)$lambda.min 

# Ajustamos la regresi칩n ridge y la regresi칩n lasso
m_ridge <- glmnet(x = training_X, y = training$Puntos, alpha = 0, lambda = lambda_ridge)

m_lasso <- glmnet(x = training_X, y = training$Puntos, alpha = 1, lambda = lambda_ridge)
coefficients(m_lasso)
```

```{r}
modelos <- data.frame(Modelo = c("Modelo Ridge", "Modelo Lasso", "Modelo MCO"),
                      Lambda = c(round(lambda_ridge, 3), round(lambda_lasso, 3), "-"),
                      Ajuste = c("m_ridge", "m_lasso", "m1"))

modelos$Modelo <- factor(modelos$Modelo, levels = c("Modelo Ridge", "Modelo Lasso", "Modelo MCO"))

Comparacion <- modelos %>% 
  group_by(Modelo, Lambda) %>% 
  summarise(Intercept = round(coefficients(get(Ajuste))[1], 2),
            Dobles = round(coefficients(get(Ajuste))[2], 2),
            Triples = round(coefficients(get(Ajuste))[3], 2),
            Robos = round(coefficients(get(Ajuste))[4], 2),
            Juegos = round(coefficients(get(Ajuste))[5], 2))

kable(Comparacion, caption = "Tabla N춿4: Comparaci칩n de los coeficientes estimados por los 3 modelos") %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

Al analizar la Tabla N춿4, puede verse que los valores 칩ptimos de $\lambda$ var칤an mucho seg칰n se trata de la regresi칩n Ridge o del m칠todo de Lasso. Respecto a los coeficientes estimados vemos que, como indica la teor칤a, en general han reducido su valor. En el caso de la regresi칩n Ridge destaca que se invirtieron los signos del intercepto y la variable juegos. En el caso de Lasso, destaca que el coeficiente de juegos lo forz칩 a ser igual a 0 y eso trajo aparejado un aumento importante en el valor del intercepto.

## Capacidad predictiva

Una vez presentado el ajuste de los 3 modelos, se evalu칩 su poder predictivo en base al error cuadr치tico medio en el conjunto de testeo.

```{r}
testing_X <- testing %>% 
  select(Dobles, Triples, Robos, Juegos) %>% 
  as.matrix()

pred_ridge <- predict(m_ridge, testing_X)
pred_lasso <- predict(m_lasso, testing_X)
pred_MCO <- predict(m1, testing)

MSE_ridge <- mean((testing$Puntos-pred_ridge)^2)
MSE_lasso <- mean((testing$Puntos-pred_lasso)^2)
MSE_MCO <- mean((testing$Puntos-pred_MCO)^2)

modelos$MSE = c(MSE_ridge, MSE_lasso, MSE_MCO)

kable(modelos[,c(1,4)], caption = "Tabla N춿5: Comparaci칩n de la capacidad predictiva de los 3 modelos") %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

Sorprendentemente, la Tabla N춿5 muestra que el mejor ajuste fue el de m칤nimos cuadrados ordinarios, el cual presenta un error 60% menor al de los modelos de Ridge y Lasso. Esto nos indica que, a pesar de que no se cumplan los supuestos y hayamos identificado posibles problemas de colinealidad, a la hora de predecir m칤nimo cuadrados fue m치s performante que el resto.

# Regresi칩n Log칤stica

## Creaci칩n de nueva variable

Se procede a crear una nueva variable binaria llamada Puntos_200 la cual toma valor 1 si Puntos \>= 200, 0 caso contrario.

```{r}
data <- data %>%
  mutate(
    Puntos_200 = factor(ifelse(Puntos>=200, 1, 0))
    )
```

Con esta nueva variable, se procede a dividir el dataset nuevamente como en el comienzo de este trabajo. Si bien el punto anterior podr칤a haberse hecho en los datasets ya separados, es conveniente hacerlo en el dataset original y generar la partici칩n con la funci칩n `createDataPartition` ya que garantiza que la representaci칩n de las categor칤as sea pareja en training y testing.

```{r}
# Divisi칩n en training y testing
set.seed(4567)
#index_training <- sample(1:nrow(data), size = 0.7*nrow(data))
index_training <- createDataPartition(data$Puntos_200, p = 0.7)
training <- data[index_training$Resample1,]
testing <- data[-index_training$Resample1,]
```

## Modelo de Regresi칩n Log칤stica

Creada la variable binaria y dividido el dataset en training y testing, se ajust칩 el modelo de regresi칩n log칤stica para predecir la probabilidad de que una jugadora anote m치s de 200 puntos en base a la cantidad de dobles, la cantidad de triples, la cantidad de robos y los partidos jugados.

```{r}
m_logistica <- glm(Puntos_200 ~ Dobles + Triples + Robos + Juegos, family = "binomial", data = training)

```

### Interpretaci칩n

```{r}
Betas = data.frame(Variable = names(coef(m_logistica)),
                   Betas = round(as.numeric(coef(m_logistica)), 2),
                   RO = round(exp(as.numeric(coef(m_logistica))), 2),
                   P_value = as.numeric(coef(summary(m_logistica))[, "Pr(>|z|)"]))

kable(Betas, caption = "Tabla N춿6: Coeficientes y razones de odds estimados del modelo") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

A partir de la Tabla N춿6 puede verse que solo resultan significativos los efectos de las variables Dobles y Triples. A continuaci칩n se presenta su interpretaci칩n:

-   Por cada doble extra que anote una jugadora, sus chances de anotar m치s de 200 puntos en la temporada aumentan un 52%.

-   Por cada triple extra que anote una jugadora, sus chances de anotar m치s de 200 puntos en la temporada aumentan un 75%.

### Punto de corte 칩ptimo y evaluaci칩n del modelo

Definido el modelo, se busc칩 el punto de corte 칩ptimo y se evalu칩 su performance en el conjunto de testing.

```{r}
curvaROC <- roc(
  response = training$Puntos_200,
  predictor = fitted.values(m_logistica),
  quiet = TRUE
)

plot(curvaROC, print.auc = TRUE)

pdc = pROC::coords(curvaROC, "best", ret = "threshold")

```

```{r}
testing$Predichos <- factor(ifelse(predict(m_logistica, newdata = testing, type = "response") >= pdc$threshold, 1, 0))

library(janitor)

tabyl(dat = testing, Puntos_200, Predichos) %>% 
  adorn_totals(where = c("row", "col"))

metricas = confusionMatrix(data = testing$Predichos, reference = testing$Puntos_200, positive = "1", mode = "everything",)

medidas = data.frame(Precisi칩n = round(as.numeric(metricas$overall[1]), 3),
                     Sensibilidad = round(as.numeric(metricas$byClass[1]), 3),
                     Especificidad = round(as.numeric(metricas$byClass[2]), 3),
                     VPP = round(as.numeric(metricas$byClass[3]), 3),
                     VPN = round(as.numeric(metricas$byClass[4]), 3),
                     Kappa = round(as.numeric(metricas$overall[2]), 3),
                     "F1-Score" = round(as.numeric(metricas$byClass[7]), 3))

kable(medidas, caption = paste0("Tabla N춿7: Medidas de ajuste del modelo con un punto de corte ", round(pdc$threshold, 3))) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

A continuaci칩n se interpretan las medidas presentadas en la Tabla N춿7:

-   **Precisi칩n:** El modelo predice correctamente al 96,3% de las jugadoras.

-   **Sensibilidad:** El modelo predice correctamente al 95,7% de las jugadoras que anotaron m치s de 200 puntos en la temporada.

-   **Especificidad:** El modelo predice correctamente al 96,8% de las jugadoras que anotaron menos de 200 puntos en la temporada.

-   **VPP:** El 95,7% de las jugadoras que el modelo predice que anotaron m치s de 200 puntos efectivamente lo hicieron en la realidad.

-   **VPN:** El 96,8% de las jugadoras que el modelo predice que no anotaron m치s de 200 puntos efectivamente no lo hicieron en la realidad.

-   **Kappa:** Dado que el coeficiente kappa dio cercano a 1, se puede decir que el ajuste del modelo es muy bueno.

-   **F1-Score:** Dado que la sensibilidad y el VPP nos dieron iguales, el valor de F1 score tambi칠n coincide. Nuevamente, este valor indica un muy buen ajuste del modelo.
