---
title: "Trabajo Pr√°ctico Final"
format:
  html:
    embed-resources: true
lang: es 
editor: visual
editor_options: 
  chunk_output_type: console
execute: 
  echo: false
  warning: false
  error: true
---

```{=html}
<style>
@media print {
  button {
    display: none;
  }
}
</style>
```
<button onclick="window.print()">

üìÑ Exportar a PDF

</button>

# Introducci√≥n

El b√°squetbol es uno de los deportes m√°s populares en los Estados Unidos. Adem√°s de su destacad√≠sima liga masculina NBA, se encuentra su similar femenina, la altamente competitiva, WNBA. El siguiente trabajo busca demostrar conocimientos aprendidos en la materia Regresi√≥n avanzada a partir de un dataset de esta ultima liga mencionada.

# Dataset

```{r}
# Librer√≠as
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(broom)
library(egg)
library(ggpubr)
library(car)
library(glmnet)
library(caret)
library(pROC)
```

## Importaci√≥n de datos

Se procede a cargar los datos y a mostrar un summary de los mismos:

```{r}
data <- read.csv("files/WNBA.csv", sep = ";")
summary(data)
```

```{r}
data$Equipo <- as.factor(data$Equipo)
data$Posicion <- as.factor(data$Posicion)
summary(data)
```

## Breve an√°lisis

Luego de importar los datos, se procede a hacer un breve an√°lisis.

### Vac√≠os y duplicados

A trav√©s del summary se puede ver que las variables num√©ricas est√°n correctamente definidas, sin NAs. Los mismo para Equipo y Posici√≥n. Se procede a analizar si existen jugadoras campo Jugadora vac√≠o. El resultado de aplicar los filtros correspondientes es el siguiente:

```{r}
paste0("Hay ",count(data %>% filter(Jugadora == "")), " registros vac√≠os")
```

Una vez checkeado esto, viendo que no hay vac√≠os, vemos si hay alguna jugadora repetida.

```{r}
data[duplicated(data$Jugadora),][,c("Jugadora", "Equipo")]
```

Vemos que existen jugadoras que aparecen m√°s de una vez, pero parece ser que se encuentran en equipos diferentes. Para eso, contamos la cantidad de veces que se encuentra duplicado Jugadora + Equipo, con el resultado que sigue:

```{r}
print(count(data[duplicated(data[, c("Jugadora", "Equipo")]), ]))
```

Por ende, podemos entender que cada vez que aparece una jugadora se da en otro club. Esto tambi√©n puede llevar a diferentes condiciones de goleo como as√≠ tambi√©n otro momento de la carrera profesional, por lo que se decide conservar los datos tal cual se encuentran.

### Entendiendo el dataset

Una vez avanzada la etapa anterior, vamos a ver brevemente c√≥mo se encuentran distribuidos los datos.

```{r}
ggplot(data, aes(x = Equipo)) +
  geom_bar(fill = "grey", color = "black") +
  labs(title = "Equipos",
       x = "Equipo",
       y = "Frecuencia") +
  theme_minimal()
```

```{r}
ggplot(data, aes(x = Posicion)) +
  geom_bar(fill = "grey", color = "black") +
  labs(title = "Equipos",
       x = "Posici√≥n",
       y = "Frecuencia") +
  theme_minimal()
```

Se puede observar como es similar la distribuci√≥n de jugadoras por equipo, mientras que abundan mayormente posiciones de Escolta, seguido de Alero y luego Pivot. El tener pocos datos de Pivots no es algo irracional, ya que es es la posici√≥n que menos jugadoras suele haber.

```{r}
skimr::skim(data %>% select(where(is.numeric)))
```

Analizando las variables cuantitativas vemos en primer lugar que no hay valores negativos, lo cual es coherente y requerido. Mientras que la mayor√≠a de las distribuciones son asim√©tricas hacia la derecha, se puede observar como la cantidad de juegos es la √∫nica que no respeta este patr√≥n. Resulta apropiado ver c√≥mo el histograma de dobles y triples es muy parecido en la forma de la distribuci√≥n como as√≠ tambi√©n el resultante natural de los puntos.

Tambi√©n es interesante comparar medias de Triples y Dobles con Puntos. Si se realizar r√°pidamente Triples x 3 + Dobles x 2 (en medias), se obtiene un valor de 186.7, lejano al 226 de los Puntos, por lo que podr√≠amos entender, a priori, que los libres (tiros individuales de 1 punto) tiene peso en el goleo de las jugadoras.

# Modelos de Regresi√≥n Lineal

Para comenzar a trabajar en los modelos de regresi√≥n lineal, se procede a dividir el dataset en train/test. Se define una semilla para hacer reproducible el experimento y se define, por consigna, que el train contenga el 70% de los datos, mientras que lo restante queda para test.

```{r}
# Divisi√≥n en training y testing
set.seed(45672848)
index_training <- sample(1:nrow(data), size = 0.7*nrow(data))

training <- data[index_training,]
testing <- data[-index_training,]
```

Se procede, luego, a obtener tres modelos mediante los siguientes criterios: - Usando stepwise regression - Criterios propios - Preguntando al famoso ChatGPT

## Stepwise regression

Para el primer caso se busca obtener un modelo de regresi√≥n en el que las variables a utilizar se definan por el proceso autom√°tico de Stepwise regression, ya que utilizar la t√©cnica del mejor subconjunto llevar√≠a a un n√∫mero muy grande de modelos a comprar y se opta por esta t√©cnica que si bien no garantiza encontrar el √≥ptimo, puede darnos una buena primera aproximaci√≥n. Para el an√°lisis se quitan del dataset el nombre de la jugadora y el equipo, ya que dichas variables cuentan con una gran cantidad de categor√≠as. En caso de incluirlas, se obtendr√≠an estimaciones muy pobres debido a los escasos grados de libertad, o incluso podr√≠a llegar el caso que sea imposible estimar el modelo.

```{r}
training_filtered <- select(training, -Jugadora, -Equipo)
m1 <- MASS::stepAIC(
  object = lm(Puntos ~ 1, data = training_filtered), #punto de partida
  scope = list(upper = lm(Puntos ~ ., data = training_filtered)), #m√°ximo modelo posible
  direction = "both", #m√©todo de selecci√≥n
  trace = FALSE, #para no imprimir resultados parciales
  k = 2, #penalizaci√≥n a emplear (2 = AIC, log(n) = BIC)
  steps = 1000 #m√°ximo nro de pasos
  )

summary(m1)
```

El resultado devuelve la utilizaci√≥n de Dobles, Triples, Robos y Juegos.

## Criterios propios

Observando el dataset, se plantea un modelo donde los puntos se basen en dobles y triples, y debido a que deber√≠a de haber una diferencia (por los libres), se plantea la posici√≥n, la cual determinar√≠a la tendencia de un jugador a recibir faltas de tiro.

```{r}
m2 <- lm(Puntos ~ Dobles + Triples + Posicion, data = training_filtered)

summary(m2)
```

## ChatGPT

Para este tercer modelo, se le ha preguntado (o desafiado) a ChatGPT a recomendar cu√°l ser√≠a el mejor modelo. La respuesta fue incluir Dobles, Triples, Minutos, Asistencias, Rebotes y Posicion.

```{r}
m3 <- lm(Puntos ~ Triples + Dobles + Minutos + Asistencias + Rebotes + Posicion, data = training)
summary(m3)
```

## Comparaci√≥n de modelos

Se procede a comparar los modelos planteados comparando CME, PRESS, Cp, AIC y BIC.

```{r}
modelos <- data.frame(Modelo = c("Modelo 1", "Modelo 2", "Modelo 3"),
                      Ajuste = c("m1", "m2", "m3"))
```

```{r}
Modelo_completo <- lm(Puntos ~ . -Jugadora - Equipo, data = training)
sigma <- sum(residuals(Modelo_completo)^2)/df.residual(Modelo_completo)

Resumen <- modelos %>% 
  group_by(Modelo) %>% 
  summarise(CME = summary(get(Ajuste))$sigma^2,
            PRESS = sum((resid(get(Ajuste))/(1-hatvalues(get(Ajuste))))^2),
            Cp = sum(residuals(get(Ajuste))^2)/sigma + 2 * length(coef(get(Ajuste))) - nrow(training),
            AIC = AIC(get(Ajuste)),
            BIC = BIC(get(Ajuste)))

kable(Resumen, caption = "Tabla N¬∞1: Comparaci√≥n del ajuste de los 3 modelos") %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

Con los datos obtenidos se puede pensar en elegir entre el Modelo 1 y Modelo 2. El Modelo 1 es el que mejores resultados en las m√©tricas de performance, mientras que el Modelo 2 es apenas peor, pero es m√°s simple. Para este caso, se decide quedarse con el Modelo 1.

## An√°lisis de residuos

Ya con el Modelo 1 elegido, se procede a evaluar los supuestos a trav√©s de los residuos.

```{r}
Modelo_final <- augment(m1)
g1 <- ggplot(mapping = aes(sample = Modelo_final$.resid)) + 
    stat_qq(color = "dodgerblue") + 
    stat_qq_line() + 
  ggtitle("QQ Normal") +
  xlab("Cuantiles te√≥ricos") +
  ylab("Cuantiles muestrales") +
  geom_text(aes(x = 2, y = -50, fill ="black", label = paste0("p-value \n", round(shapiro.test(Modelo_final$.resid)$p.value, 8)))) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "none")

g2 <- ggplot(Modelo_final) +
  aes(x = .fitted, y = .std.resid) +
  geom_point(color = "dodgerblue") +
  geom_hline(yintercept = 0, color = "black") +
  ggtitle("Residuos vs. Predichos") +
  xlab("Valores predichos") +
  ylab("Residuos estandarizados") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

g <- ggarrange(g1, g2, ncol = 2)

annotate_figure(g, top = text_grob("Gr√°fico N¬∞1: Comprobaci√≥n de supuestos", face = "bold", size = 14))
```

En el gr√°fico N¬∞1 se observa que la distribuci√≥n de los mismos presenta colas pesadas y que no se verifica el supuesto de variancia constante. En caso de querer solucionarlo, podr√≠a optarse por utilizar una transformaci√≥n de la variables respuesta como el $log(Y)$ o bien aplicar el m√©todo de Box y Cox. Por otro lado, tambi√©n se observa a un posible valor at√≠pico.

Luego se procede a analizar colinealidad

```{r}
# Colinealidad
training_modelo <- training %>% 
  select(Juegos, Minutos, Triples, Dobles)

corr_matrix <- cor(training_modelo)

corr_melted <- reshape2::melt(corr_matrix)

ggplot(corr_melted, aes(x = Var2, y = Var1, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), size = 3) +
  scale_fill_gradient2(low = "#ef2947", high = "#009929", mid = "white", midpoint = 0) +
  labs(x = "", y = "", title = "Gr√°fico N¬∞2: Matriz de correlaci√≥n") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

Analizando las correlaciones lineales entre variables se observa que minutos est√° muy relacionada linealmente con todas las restantes.

```{r}
vif = vif(m1)

vif_df <- data.frame(Variable = names(vif),
                     VIF = as.numeric(vif),
                     row.names = NULL)

kable(vif_df, caption = "Tabla N¬∞2: Factores de Inflaci√≥n de la Varianza (VIF)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

Al analizar la tabla N¬∞2, se ve que, a pesar de que las variables est√©n altamente correlacionadas, esto no tiene un impacto tan importante ya que ning√∫n VIF es mayor a 5.

```{r}
# Observaciones at√≠picas
Modelo_final <- mutate(Modelo_final, 
                       PRESS = .resid/(1-.hat),
                       id = 1:nrow(Modelo_final))

g1 <- ggplot(data = Modelo_final) + 
    aes(x = id, y = PRESS) + 
  geom_bar(stat="identity", color = "dodgerblue", fill = "dodgerblue")+
    geom_hline(aes(yintercept = 0)) +
    ggtitle("Residuos PRESS") +
    xlab("Observaci√≥n") +
    ylab("PRESS") +
    theme_bw() +
    theme(legend.position = "none",
          plot.title = element_text(hjust = 0.5))

# Observaciones influyentes
g2 <- ggplot(data = Modelo_final) +
    aes(x = id, y = .cooksd) +
  geom_bar(stat="identity", color = "dodgerblue", fill = "dodgerblue")+
    ggtitle("Distancia de Cook") +
    xlab("Observaci√≥n") +
    ylab("Distancia de Cook") +
    theme_bw() +
    theme(legend.position = "none",
      plot.title = element_text(hjust = 0.5))

g <- ggarrange(g1, g2, ncol = 2)

annotate_figure(g, top = text_grob("Gr√°fico N¬∞3: Observaciones at√≠picas e influyentes", face = "bold", size = 14))
```

En el gr√°fico N¬∞3 se vuelve a ver que existe una observaci√≥n at√≠pica, la cual presenta un residuo PRESS mayor a 100. Sin embargo, al analizar la influencia de las observaciones mediante la distancia de Cook, se encuentra que ninguna tiene una influencia desmedida sobre el ajuste del modelo, ya que todas son menores a 1.

## Interpretaci√≥n del modelo

```{r}
Betas = data.frame(Variable = names(coef(m1)),
                   Valor = as.numeric(coef(m1)),
                   P_value = as.numeric(coef(summary(m1))[, "Pr(>|t|)"]))

kable(Betas, caption = "Tabla N¬∞3: Coeficientes estimados del modelo") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

A trav√©s de la Tabla N¬∞3 se puede interpretar nuestro modelo elegido:

-   El valor estimado del intercepto es de 2.68 aproximadamente. Igual as√≠, el pvalue resulta de no poder descartar la hip√≥tesis de que el intercepto es igual a 0. Recordando la interpretaci√≥n del mismo, se pensar√≠a que es el valor de puntos promedio para 0 dobles, 0 triples, 0 robos y 0 juegos. Lo cual no resulta para nada il√≥gico pensar que este valor sea 0 en la realidad y que estad√≠sticamente nos de dicho indicio.

Los dem√°s predictores tienen un pvalue \<0.01, algunos con ordenes mucho menores, por lo que podemos rechazar la hipotesis de nula. Respecto a sus valores predichos podemos decir que:

-   Por cada doble convertido, los puntos de una jugadora aumentan en promedio en una suma de 2.40, manteniendose todas las dem√°s variables constantes.
-   Por cada triple convertido, los puntos de una jugadora aumentan en promedio en una suma de 3.46, manteniendose todas las dem√°s variables constantes.
-   Por cada robo conseguido, los puntos de una jugadora aumentan en promedio en una suma de 0.74, manteniendose todas las dem√°s variables constantes.
-   Por cada juego jugado, los puntos de una jugadora disminuyen en promedio en una suma de 0.51, manteniendose todas las dem√°s variables constantes.

Estas interpretaciones nos dejan insights interesantes de analizar. Si bien dobles y triples suman 2 y 3 puntos respectivamente en el juego, que el valor que afectan al promedio sea mayor puede estar indicando que en cierto modo, estos coeficientes est√°n absorbiendo el efecto de los tiros libres. Lo mismo podemos pensar acerca del robo, ya que cuando se da el mismo, en el desorden del juego, es probable que quien roba reciba una falta. Por √∫ltimo, el valor al aumentar la cantidad de juegos podr√≠a estar dando indicio de desgaste f√≠sico de las jugadoras, o bien podr√≠a ser que, a pesar de haber encontrado que la multicolinealidad no era muy importante, en realidad si nos est√° afectando a la estimaci√≥n de este coeficiente, que a priori uno esperar√≠a que fuera positivo.

# M√©todos de Regularizaci√≥n

Una vez identificado el mejor modelo de regresi√≥n con el ajuste de m√≠nimos cuadrados ordinarios, se opt√≥ por evaluar la posibilidad de utilizar m√©todos de regularizaci√≥n. Esto se hizo con el objetivo de intentar mejorar la capacidad predictiva, bas√°ndose en la idea del *trade-off* entre sesgo y variancia.

Para realizar tanto el ajuste mediante la regresi√≥n ridge, como por el m√©todo de lasso, primero se busc√≥ el mejor valor de $\lambda$ utilizando *5-fold Cross-Validation.*

Los resultados de los ajustes junto con los valores de $\lambda$ utilizados, son presentados a continuaci√≥n:

```{r}
# Preparamos la matriz de predictores
training_X <- training %>% 
  select(Dobles, Triples, Robos, Juegos) %>% 
  as.matrix()

# Buscamos el lambda √≥ptimo para ridge y lasso
lambda_ridge <- cv.glmnet(training_X, training$Puntos, nfolds = 5, alpha = 0)$lambda.min 

lambda_lasso <- cv.glmnet(training_X, training$Puntos, nfolds = 5, alpha = 1)$lambda.min 

# Ajustamos la regresi√≥n ridge y la regresi√≥n lasso
m_ridge <- glmnet(x = training_X, y = training$Puntos, alpha = 0, lambda = lambda_ridge)

m_lasso <- glmnet(x = training_X, y = training$Puntos, alpha = 1, lambda = lambda_ridge)
coefficients(m_lasso)
```

```{r}
modelos <- data.frame(Modelo = c("Modelo Ridge", "Modelo Lasso", "Modelo MCO"),
                      Lambda = c(round(lambda_ridge, 3), round(lambda_lasso, 3), "-"),
                      Ajuste = c("m_ridge", "m_lasso", "m1"))

modelos$Modelo <- factor(modelos$Modelo, levels = c("Modelo Ridge", "Modelo Lasso", "Modelo MCO"))

Comparacion <- modelos %>% 
  group_by(Modelo, Lambda) %>% 
  summarise(Intercept = round(coefficients(get(Ajuste))[1], 2),
            Dobles = round(coefficients(get(Ajuste))[2], 2),
            Triples = round(coefficients(get(Ajuste))[3], 2),
            Robos = round(coefficients(get(Ajuste))[4], 2),
            Juegos = round(coefficients(get(Ajuste))[5], 2))

kable(Comparacion, caption = "Tabla N¬∞4: Comparaci√≥n de los coeficientes estimados por los 3 modelos") %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

Al analizar la Tabla N¬∞4, puede verse que los valores √≥ptimos de $\lambda$ var√≠an mucho seg√∫n se trata de la regresi√≥n Ridge o del m√©todo de Lasso. Respecto a los coeficientes estimados vemos que, como indica la teor√≠a, en general han reducido su valor. En el caso de la regresi√≥n Ridge destaca que se invirtieron los signos del intercepto y la variable juegos. En el caso de Lasso, destaca que el coeficiente de juegos lo forz√≥ a ser igual a 0 y eso trajo aparejado un aumento importante en el valor del intercepto.

## Capacidad predictiva

Una vez presentado el ajuste de los 3 modelos, se evalu√≥ su poder predictivo en base al error cuadr√°tico medio en el conjunto de testeo.

```{r}
testing_X <- testing %>% 
  select(Dobles, Triples, Robos, Juegos) %>% 
  as.matrix()

pred_ridge <- predict(m_ridge, testing_X)
pred_lasso <- predict(m_lasso, testing_X)
pred_MCO <- predict(m1, testing)

MSE_ridge <- mean((testing$Puntos-pred_ridge)^2)
MSE_lasso <- mean((testing$Puntos-pred_lasso)^2)
MSE_MCO <- mean((testing$Puntos-pred_MCO)^2)

modelos$MSE = c(MSE_ridge, MSE_lasso, MSE_MCO)

kable(modelos[,c(1,4)], caption = "Tabla N¬∞5: Comparaci√≥n de la capacidad predictiva de los 3 modelos") %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

Sorprendentemente, la Tabla N¬∞5 muestra que el mejor ajuste fue el de m√≠nimos cuadrados ordinarios, el cual presenta un error 60% menor al de los modelos de Ridge y Lasso. Esto nos indica que, a pesar de que no se cumplan los supuestos y hayamos identificado posibles problemas de colinealidad, a la hora de predecir m√≠nimo cuadrados fue m√°s performante que el resto.

# Regresi√≥n Log√≠stica

## Creaci√≥n de nueva variable

Se procede a crear una nueva variable binaria llamada Puntos_200 la cual toma valor 1 si Puntos \>= 200, 0 caso contrario.

```{r}
data <- data %>%
  mutate(
    Puntos_200 = factor(ifelse(Puntos>=200, 1, 0))
    )
```

Con esta nueva variable, se procede a dividir el dataset nuevamente como en el comienzo de este trabajo. Si bien el punto anterior podr√≠a haberse hecho en los datasets ya separados, es conveniente hacerlo en el dataset original y generar la partici√≥n con la funci√≥n `createDataPartition` ya que garantiza que la representaci√≥n de las categor√≠as sea pareja en training y testing.

```{r}
# Divisi√≥n en training y testing
set.seed(4567)
#index_training <- sample(1:nrow(data), size = 0.7*nrow(data))
index_training <- createDataPartition(data$Puntos_200, p = 0.7)
training <- data[index_training$Resample1,]
testing <- data[-index_training$Resample1,]
```

## Modelo de Regresi√≥n Log√≠stica

Creada la variable binaria y dividido el dataset en training y testing, se ajust√≥ el modelo de regresi√≥n log√≠stica para predecir la probabilidad de que una jugadora anote m√°s de 200 puntos en base a la cantidad de dobles, la cantidad de triples, la cantidad de robos y los partidos jugados.

```{r}
m_logistica <- glm(Puntos_200 ~ Dobles + Triples + Robos + Juegos, family = "binomial", data = training)

```

### Interpretaci√≥n

```{r}
Betas = data.frame(Variable = names(coef(m_logistica)),
                   Betas = round(as.numeric(coef(m_logistica)), 2),
                   RO = round(exp(as.numeric(coef(m_logistica))), 2),
                   P_value = as.numeric(coef(summary(m_logistica))[, "Pr(>|z|)"]))

kable(Betas, caption = "Tabla N¬∞6: Coeficientes y razones de odds estimados del modelo") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

A partir de la Tabla N¬∞6 puede verse que solo resultan significativos los efectos de las variables Dobles y Triples. A continuaci√≥n se presenta su interpretaci√≥n:

-   Por cada doble extra que anote una jugadora, sus chances de anotar m√°s de 200 puntos en la temporada aumentan un 52%.

-   Por cada triple extra que anote una jugadora, sus chances de anotar m√°s de 200 puntos en la temporada aumentan un 75%.

### Punto de corte √≥ptimo y evaluaci√≥n del modelo

Definido el modelo, se busc√≥ el punto de corte √≥ptimo y se evalu√≥ su performance en el conjunto de testing.

```{r}
curvaROC <- roc(
  response = training$Puntos_200,
  predictor = fitted.values(m_logistica),
  quiet = TRUE
)

plot(curvaROC, print.auc = TRUE)

pdc = pROC::coords(curvaROC, "best", ret = "threshold")

```

```{r}
testing$Predichos <- factor(ifelse(predict(m_logistica, newdata = testing, type = "response") >= pdc$threshold, 1, 0))

library(janitor)

tabyl(dat = testing, Puntos_200, Predichos) %>% 
  adorn_totals(where = c("row", "col"))

metricas = confusionMatrix(data = testing$Predichos, reference = testing$Puntos_200, positive = "1", mode = "everything",)

medidas = data.frame(Precisi√≥n = round(as.numeric(metricas$overall[1]), 3),
                     Sensibilidad = round(as.numeric(metricas$byClass[1]), 3),
                     Especificidad = round(as.numeric(metricas$byClass[2]), 3),
                     VPP = round(as.numeric(metricas$byClass[3]), 3),
                     VPN = round(as.numeric(metricas$byClass[4]), 3),
                     Kappa = round(as.numeric(metricas$overall[2]), 3),
                     "F1-Score" = round(as.numeric(metricas$byClass[7]), 3))

kable(medidas, caption = paste0("Tabla N¬∞7: Medidas de ajuste del modelo con un punto de corte ", round(pdc$threshold, 3))) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

A continuaci√≥n se interpretan las medidas presentadas en la Tabla N¬∞7:

-   **Precisi√≥n:** El modelo predice correctamente al 96,3% de las jugadoras.

-   **Sensibilidad:** El modelo predice correctamente al 95,7% de las jugadoras que anotaron m√°s de 200 puntos en la temporada.

-   **Especificidad:** El modelo predice correctamente al 96,8% de las jugadoras que anotaron menos de 200 puntos en la temporada.

-   **VPP:** El 95,7% de las jugadoras que el modelo predice que anotaron m√°s de 200 puntos efectivamente lo hicieron en la realidad.

-   **VPN:** El 96,8% de las jugadoras que el modelo predice que no anotaron m√°s de 200 puntos efectivamente no lo hicieron en la realidad.

-   **Kappa:** Dado que el coeficiente kappa dio cercano a 1, se puede decir que el ajuste del modelo es muy bueno.

-   **F1-Score:** Dado que la sensibilidad y el VPP nos dieron iguales, el valor de F1 score tambi√©n coincide. Nuevamente, este valor indica un muy buen ajuste del modelo.
